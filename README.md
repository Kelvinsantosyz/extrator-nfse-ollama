# ü§ñ Extrator Inteligente de NFS-e com OCR e LLM

Este projeto utiliza tecnologias de Reconhecimento √ìptico de Caracteres (OCR) e Modelos de Linguagem Grandes (LLMs) locais (via Ollama) ou na nuvem (Azure) para extrair dados estruturados de Notas Fiscais de Servi√ßo eletr√¥nicas (NFS-e) brasileiras, armazenando-os numa base de dados MySQL. Uma interface web constru√≠da com Streamlit permite o upload, processamento, visualiza√ß√£o, edi√ß√£o e gest√£o dos dados e utilizadores.

---

**‚ö†Ô∏è Nota Importante sobre Precis√£o**

Nenhum sistema de OCR ou LLM √© 100% perfeito, especialmente com a variedade de layouts e a qualidade vari√°vel dos documentos digitalizados (incluindo imagens como PNG, JPEG, WEBP).
* **OCR (Azure, Ollama, EasyOCR):** Pode haver erros na leitura de caracteres (ex: "5" confundido com "S", "1" com "I"), especialmente em imagens de baixa resolu√ß√£o ou com texto sobreposto.
* **Extra√ß√£o LLM (Ollama/Phi3):** O modelo pode, ocasionalmente, interpretar mal o texto do OCR, confundir campos (Prestador vs. Tomador), omitir informa√ß√µes ou gerar um JSON inv√°lido, principalmente se o texto do OCR contiver muitos erros.

**√â crucial utilizar a funcionalidade de valida√ß√£o e edi√ß√£o (`st.data_editor`) fornecida na interface para verificar e corrigir os dados extra√≠dos *antes* de os salvar na base de dados.** O objetivo da IA aqui √© acelerar o processo, mas a revis√£o humana continua a ser fundamental para garantir a precis√£o final dos dados. O fine-tuning do LLM pode *aumentar significativamente* a precis√£o da extra√ß√£o para os *seus* tipos de documento, mas a valida√ß√£o ainda √© recomendada.

---

## ‚ú® Funcionalidades

* **Upload Flex√≠vel:** Carregue ficheiros PDF, PNG, JPG, JPEG ou WEBP individualmente ou processe todos os ficheiros compat√≠veis numa pasta.
* **M√∫ltiplas Op√ß√µes de OCR:** Escolha o motor de OCR que melhor se adapta √†s suas necessidades atrav√©s de configura√ß√£o (`.env`):
    * **Azure Computer Vision:** Servi√ßo de OCR na nuvem da Microsoft (requer subscri√ß√£o Azure). Potencialmente alta precis√£o.
    * **Ollama LMM (Local):** Utilize modelos de linguagem multimodais (como Llama 3.2 Vision, Llava, Granite) executados localmente via Ollama. Flex√≠vel, mas pode ser mais lento e consumir mais recursos.
    * **EasyOCR (Local):** Biblioteca Python especializada em OCR, otimizada para velocidade, especialmente com GPU NVIDIA.
* **Extra√ß√£o com LLM Local:** Utiliza um LLM configurado no Ollama (ex: `phi3:medium`) para analisar o texto extra√≠do pelo OCR e estrutur√°-lo num formato JSON pr√©-definido.
* **Valida√ß√£o e Edi√ß√£o:** Interface `st.data_editor` para visualizar e corrigir os dados extra√≠dos antes de salvar.
* **Armazenamento em Base de Dados:** Guarda os dados validados numa base de dados MySQL para consulta e an√°lise.
* **Consulta e Exporta√ß√£o:** Pesquise notas fiscais por diversos campos (CNPJ, Raz√£o Social, etc.) e exporte os resultados para CSV ou Excel.
* **Dashboard Financeiro:** Visualiza√ß√µes b√°sicas (Plotly) sobre totais, evolu√ß√£o mensal, top prestadores e categorias.
* **Gest√£o de Utilizadores:** Sistema de login seguro (`streamlit-authenticator`) com gest√£o de utilizadores (criar, excluir, for√ßar altera√ß√£o de senha) para administradores.
* **Preparado para Fine-Tuning:** Exporta os pares (Texto OCR Bruto, JSON Extra√≠do Bruto) em formato `.jsonl`, pronto para ser corrigido e usado para treinar um modelo LLM extrator mais preciso.

## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagem:** Python 3.10+
* **Interface Web:** Streamlit
* **LLM (Local):** Ollama (com modelos como `phi3`, `llava`, `granite`, etc.)
* **OCR (Op√ß√µes):**
    * Azure Computer Vision SDK (`azure-cognitiveservices-vision-computervision`, `msrest`)
    * Ollama (com modelos LMM)
    * EasyOCR (+ `torch`, `torchvision`, `torchaudio`)
* **Manipula√ß√£o de PDF:** PyMuPDF (`fitz`)
* **Base de Dados:** MySQL
* **Intera√ß√£o com BD:** `mysql-connector-python`, `SQLAlchemy`, `PyMySQL`
* **Autentica√ß√£o:** `streamlit-authenticator`, `bcrypt`
* **Manipula√ß√£o de Dados:** Pandas
* **Visualiza√ß√£o:** Plotly Express (`plotly`)
* **Configura√ß√£o:** `python-dotenv`
* **Imagens (Leitura base):** Pillow (geralmente instalada como depend√™ncia)

## üìö Bibliotecas Necess√°rias

Instale as bibliotecas Python listadas abaixo. √â **altamente recomendado** usar um ambiente virtual (`venv`).

**Bibliotecas Base:**
```bash
pip install streamlit pandas plotly mysql-connector-python streamlit-authenticator bcrypt python-dotenv sqlalchemy pymysql ollama PyMuPDF Pillow openpyxl xlsxwriter
````

*(Nota: `openpyxl` e `xlsxwriter` s√£o necess√°rios para exportar para Excel)*

**Depend√™ncias Espec√≠ficas de OCR (instale APENAS as que for usar):**

  * **Para Azure Computer Vision (`OCR_METHOD=AZURE`):**

    ```bash
    pip install azure-cognitiveservices-vision-computervision msrest
    ```

  * **Para EasyOCR (`OCR_METHOD=EASYOCR`):**

      * **Com Suporte GPU NVIDIA (Recomendado):**
        ```bash
        # Instale PyTorch com suporte CUDA (ajuste 'cu121' para sua vers√£o CUDA se necess√°rio)
        pip install torch torchvision torchaudio --index-url [https://download.pytorch.org/whl/cu121](https://download.pytorch.org/whl/cu121)
        pip install easyocr
        ```
      * **Apenas CPU:**
        ```bash
        pip install torch torchvision torchaudio # Pode usar a vers√£o padr√£o da CPU
        pip install easyocr
        ```
        *(Nota: EasyOCR sem GPU ser√° consideravelmente mais lento)*

  * **Para Ollama LMM (`OCR_METHOD=OLLAMA`):** Nenhuma biblioteca Python extra *al√©m do `ollama`* (j√° na lista base) √© necess√°ria, mas voc√™ precisa ter o [Ollama](https://ollama.com/) instalado e a correr no seu sistema, com os modelos LMM desejados (ex: `ollama pull llava-llama3`) j√° baixados.

## ‚öôÔ∏è Configura√ß√£o

1.  **Base de Dados MySQL:** Certifique-se de ter um servidor MySQL a correr e crie uma base de dados para este projeto.

2.  **Ficheiro `.env`:** Crie um ficheiro chamado `.env` na pasta raiz do projeto (`H:\projeto2`) e adicione as seguintes vari√°veis, substituindo pelos seus valores:

    ```dotenv
    # --- Credenciais do Banco de Dados MySQL ---
    DB_HOST=localhost
    DB_USER=seu_usuario_mysql
    DB_PASSWORD=sua_senha_mysql
    DB_NAME=seu_banco_de_dados_mysql

    # --- Escolha do M√©todo OCR ---
    # Op√ß√µes v√°lidas: AZURE, OLLAMA, EASYOCR
    # (Se omitido ou inv√°lido, o padr√£o ser√° AZURE se as credenciais estiverem dispon√≠veis, sen√£o tentar√° Ollama/EasyOCR se dispon√≠veis)
    OCR_METHOD=AZURE

    # --- Configura√ß√µes para OCR_METHOD=OLLAMA ---
    # Escolha o modelo LMM que voc√™ baixou no Ollama (ex: llava-llama3, granite3.2-vision, llava:13b)
    MODELO_LMM_OCR=llava-llama3

    # --- Credenciais Azure (Necess√°rio APENAS se OCR_METHOD=AZURE) ---
    # Descomente e preencha se for usar Azure e se N√ÉO estiverem hardcoded no processador.py
    # AZURE_CV_KEY="sua_chave_azure_aqui"
    # AZURE_CV_ENDPOINT="seu_endpoint_azure_aqui"

    # --- (Opcional) Chave Secreta para Cookies de Autentica√ß√£o ---
    # Gere uma chave aleat√≥ria longa (ex: openssl rand -hex 32)
    # AUTH_SECRET_KEY="sua_chave_secreta_aqui"
    ```

      * **Importante:** Verifique o ficheiro `Backend/processador.py` para confirmar se as credenciais Azure est√£o hardcoded ou se dependem do `.env`. Se dependerem do `.env`, descomente e preencha `AZURE_CV_KEY` e `AZURE_CV_ENDPOINT`.
      * Se `OCR_METHOD` for `OLLAMA`, certifique-se que o `MODELO_LMM_OCR` corresponde a um modelo que voc√™ baixou (`ollama pull nome_do_modelo`).
      * Se `OCR_METHOD` for `EASYOCR`, certifique-se que instalou as bibliotecas corretamente.

3.  **Ollama (Se usar OCR\_METHOD=OLLAMA ou para Extra√ß√£o LLM):**

      * Instale o [Ollama](https://ollama.com/) no seu sistema.
      * Baixe os modelos necess√°rios:
        ```bash
        # Modelo para extra√ß√£o JSON (ex: phi3)
        ollama pull phi3:medium

        # Modelo LMM para OCR (se OCR_METHOD=OLLAMA, ex: llava-llama3)
        ollama pull llava-llama3 # Ou o modelo definido em MODELO_LMM_OCR
        ```
      * Certifique-se que o servi√ßo Ollama est√° a correr antes de iniciar a aplica√ß√£o Streamlit.

## üöÄ Instala√ß√£o e Execu√ß√£o

1.  **Clone o Reposit√≥rio:**
    ```bash
    git clone <url_do_seu_repositorio>
    cd <nome_da_pasta_do_projeto> # Ex: cd projeto2
    ```
2.  **Crie e Ative um Ambiente Virtual (Recomendado):**
    ```bash
    python -m venv venv
    # Windows
    .\venv\Scripts\activate
    # Linux/macOS
    source venv/bin/activate
    ```
3.  **Instale as Depend√™ncias:**
    ```bash
    pip install -r requirements.txt # (Se voc√™ criar um ficheiro requirements.txt com as bibliotecas listadas acima)
    # Ou instale manualmente as bibliotecas necess√°rias listadas na se√ß√£o "Bibliotecas"
    ```
4.  **Configure o `.env`:** Crie e preencha o ficheiro `.env` na raiz do projeto, como descrito na se√ß√£o "Configura√ß√£o".
5.  **Execute a Aplica√ß√£o Streamlit:**
      * Certifique-se que o servi√ßo Ollama est√° a correr (se aplic√°vel).
      * Navegue at√© √† pasta `Frontend`:
        ```bash
        cd Frontend
        ```
      * Execute o Streamlit:
        ```bash
        streamlit run app.py
        ```
6.  **Primeiro Login:** A aplica√ß√£o criar√° as tabelas na base de dados automaticamente. O primeiro utilizador pode precisar de ser criado manualmente ou atrav√©s de um script inicial (n√£o inclu√≠do). Utilize as credenciais definidas para fazer login. Se for administrador, poder√° criar outros utilizadores na aba "Gerir Utilizadores".

## üìñ Uso

1.  **Login:** Aceda √† aplica√ß√£o e fa√ßa login com as suas credenciais.
2.  **Processar Documentos:**
      * Na aba "‚ûï Processar Documentos", escolha "Upload Manual" para carregar ficheiros individuais ou "Processar Pasta" para indicar um diret√≥rio no servidor.
      * Clique no bot√£o "Iniciar Processamento". A aplica√ß√£o usar√° o m√©todo OCR configurado no `.env` para ler o texto e o LLM local (Ollama) para extrair os dados.
      * Os dados extra√≠dos (brutos) ser√£o exibidos num editor de tabela (`st.data_editor`). Se a extra√ß√£o falhar, a "Resposta Bruta" do LLM ser√° exibida.
      * **Valide e Corrija:** Verifique os dados na tabela e fa√ßa as corre√ß√µes necess√°rias clicando duas vezes nas c√©lulas.
      * **Salvar:** Clique em "‚úÖ Salvar Dados Limpos na Base de Dados". Os dados ser√£o limpos (formata√ß√£o de n√∫meros, datas) e guardados no MySQL.
      * **Cancelar:** Clique em "‚ùå Cancelar Edi√ß√£o" para descartar os dados extra√≠dos sem salvar.
      * **Baixar Dados para Treino:** Clique em "üß¨ Baixar Dados para Treino (.jsonl)" para exportar o texto OCR bruto e o JSON bruto extra√≠do pelo LLM (antes da edi√ß√£o). Este ficheiro √© √∫til para fine-tuning.
3.  **Consultar Dados:**
      * Na aba "üîç Consultar Dados", utilize a barra de pesquisa para filtrar as notas fiscais por diferentes campos.
      * Visualize os resultados e baixe a consulta em formato CSV.
4.  **Dashboard Financeiro:**
      * A aba "üìä Dashboard Financeiro" apresenta gr√°ficos sobre a evolu√ß√£o mensal, top prestadores, categorias e maiores notas.
5.  **Gerir Utilizadores (Admin):**
      * Se for administrador, a aba "‚öôÔ∏è Gerir Utilizadores" permite visualizar, criar, excluir e for√ßar a altera√ß√£o de senha de outros utilizadores.

## üí° Op√ß√µes de OCR: Pr√≥s e Contras

  * **`OCR_METHOD=AZURE`**
      * **Pr√≥s:** Potencialmente a maior precis√£o, mantido pela Microsoft, bom com layouts variados.
      * **Contras:** Requer subscri√ß√£o Azure (custo associado), depende de conex√£o √† internet, pode ser mais lento que EasyOCR devido √† lat√™ncia da rede e processamento na nuvem.
  * **`OCR_METHOD=OLLAMA`**
      * **Pr√≥s:** Flexibilidade (pode testar v√°rios modelos LMM locais - Llava, Granite, etc.), processamento totalmente local (privacidade), pode ser bom com imagens complexas onde o contexto ajuda.
      * **Contras:** **Geralmente o mais lento**, consome muitos recursos locais (RAM, VRAM), a precis√£o depende muito do modelo LMM escolhido (`MODELO_LMM_OCR` no `.env`).
  * **`OCR_METHOD=EASYOCR`**
      * **Pr√≥s:** **Geralmente o mais r√°pido**, especialmente com GPU NVIDIA. Boa precis√£o para documentos padr√£o. Processamento local.
      * **Contras:** Pode ter menor precis√£o que Azure/LMMs em layouts muito complexos, texto degradado ou manuscrito (menos relevante para NFS-e). A instala√ß√£o do PyTorch com CUDA pode ser complexa.

## üöÄ Melhorias Futuras (Fine-Tuning)

A precis√£o da *extra√ß√£o* (transformar texto OCR em JSON) pode ser significativamente melhorada atrav√©s do **fine-tuning** de um modelo LLM (como `phi3:mini` ou `phi3:medium`).

1.  Processe um lote de documentos usando a aplica√ß√£o.
2.  Clique em "üß¨ Baixar Dados para Treino (.jsonl)".
3.  **Manualmente, corrija** o campo `"completion"` (que cont√©m o JSON bruto extra√≠do) em cada linha do ficheiro `.jsonl` para que fique 100% correto.
4.  Use este ficheiro `.jsonl` corrigido para fazer o fine-tuning de um modelo LLM (usando ferramentas como `unsloth`, `axolotl`, `LLaMA Factory`, etc.).
5.  Importe o seu modelo treinado para o Ollama (ex: `ollama create meu_extrator_nfse -f SeuModelfile`).
6.  Atualize a vari√°vel `modelo_usado` no ficheiro `Backend/processador.py` para usar o nome do seu modelo treinado (ex: `modelo_usado = 'meu_extrator_nfse:latest'`).
